{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ftGaqLZDbwIX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.options.display.max_rows = None\n",
        "pd.options.display.max_columns = None\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "# Assuming df is your DataFrame and 'Feature17' has missing values\n",
        "imputer = IterativeImputer(max_iter=100, tol=1e-3)\n",
        "\n",
        "df_train = pd.read_csv('../data/iith_foml_2023_train.csv')\n",
        "# Fit the imputer model on the dataset to learn the data patterns\n",
        "df_train.drop(columns=['Feature 16', 'Feature 17'], inplace=True)\n",
        "imputer.fit(df_train)\n",
        "\n",
        "# Transform the dataset to replace missing values\n",
        "df_imputed = imputer.transform(df_train)\n",
        "\n",
        "# Convert back to a DataFrame\n",
        "df_imputed = pd.DataFrame(df_imputed, columns=df_train.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = df_imputed.iloc[:, :-1]\n",
        "y_train = df_imputed.iloc[:, -1]\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Target Variable (Discrete)\n",
              "1.0     488\n",
              "0.0     249\n",
              "2.0     109\n",
              "6.0      70\n",
              "5.0      41\n",
              "8.0       7\n",
              "14.0      5\n",
              "7.0       5\n",
              "15.0      4\n",
              "4.0       3\n",
              "13.0      3\n",
              "3.0       3\n",
              "9.0       2\n",
              "12.0      1\n",
              "17.0      1\n",
              "11.0      1\n",
              "10.0      1\n",
              "16.0      1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_imputed['Target Variable (Discrete)'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdtdnmqO0WPZ",
        "outputId": "2c213020-ecde-4473-fe3e-83fffe5e02e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of train_x: (795, 22)\n",
            "Shape of val_x: (199, 22)\n",
            "Shape of train_y: (795,)\n",
            "Shape of val_y: (199,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_x, val_x, train_y, val_y = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Shape of train_x:\", train_x.shape)\n",
        "print(\"Shape of val_x:\", val_x.shape)\n",
        "print(\"Shape of train_y:\", train_y.shape)\n",
        "print(\"Shape of val_y:\", val_y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "G0yQh6pPAMKB",
        "outputId": "3d7c2cb2-fa37-4085-aec0-a3d59ecb7f46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Accuracy: 0.7839195979899497\n",
            "Model Macro F1 Score: 0.3424524681667539\n",
            "\n",
            "Model Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.80      0.82        50\n",
            "         1.0       0.81      0.97      0.88        91\n",
            "         2.0       0.54      0.58      0.56        26\n",
            "         3.0       0.00      0.00      0.00         1\n",
            "         4.0       0.00      0.00      0.00         1\n",
            "         5.0       0.50      0.12      0.20         8\n",
            "         6.0       1.00      1.00      1.00        11\n",
            "         7.0       0.00      0.00      0.00         2\n",
            "         8.0       0.00      0.00      0.00         5\n",
            "        11.0       0.00      0.00      0.00         1\n",
            "        13.0       0.00      0.00      0.00         1\n",
            "        14.0       1.00      1.00      1.00         1\n",
            "        15.0       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.78       199\n",
            "   macro avg       0.36      0.34      0.34       199\n",
            "weighted avg       0.73      0.78      0.75       199\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "# Initialize Adaboost model\n",
        "model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(train_x, train_y)\n",
        "\n",
        "# Make predictions on the validation data\n",
        "predictions = model.predict(val_x)\n",
        "\n",
        "# Calculate accuracy and macro F1 score\n",
        "accuracy = accuracy_score(val_y, predictions)\n",
        "macro_f1 = f1_score(val_y, predictions, average='macro', zero_division=0.0)\n",
        "\n",
        "# Display results\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "print(\"Model Macro F1 Score:\", macro_f1)\n",
        "\n",
        "# Classification report for more details\n",
        "classification_rep = classification_report(val_y, predictions, zero_division=0.0)\n",
        "print(\"\\nModel Classification Report:\\n\", classification_rep)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
