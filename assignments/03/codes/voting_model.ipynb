{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.options.display.max_rows = None\n",
        "pd.options.display.max_columns = None\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "# Assuming df is your DataFrame and 'Feature17' has missing values\n",
        "imputer = IterativeImputer(max_iter=100, tol=1e-3)\n",
        "\n",
        "df_train = pd.read_csv('../data/iith_foml_2023_train.csv')\n",
        "# Fit the imputer model on the dataset to learn the data patterns\n",
        "df_train.drop(columns=['Feature 16', 'Feature 17'], inplace=True)\n",
        "imputer.fit(df_train)\n",
        "\n",
        "# Transform the dataset to replace missing values\n",
        "df_imputed = imputer.transform(df_train)\n",
        "\n",
        "# Convert back to a DataFrame\n",
        "df_imputed = pd.DataFrame(df_imputed, columns=df_train.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_sample_weight, compute_class_weight\n",
        "\n",
        "X_train = df_imputed.iloc[:, :-1]\n",
        "y_train = df_imputed.iloc[:, -1]\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "class_wts = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_wts_dict = dict(zip(np.arange(len(class_wts)), class_wts))\n",
        "sample_wts = compute_sample_weight(class_weight=class_wts_dict, y=y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "G0yQh6pPAMKB",
        "outputId": "3d7c2cb2-fa37-4085-aec0-a3d59ecb7f46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.98      0.91        50\n",
            "           1       0.95      0.97      0.96        98\n",
            "           2       0.76      0.73      0.74        22\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       1.00      0.62      0.77         8\n",
            "           6       1.00      1.00      1.00        14\n",
            "           7       0.00      0.00      0.00         1\n",
            "           8       0.00      0.00      0.00         1\n",
            "           9       0.00      0.00      0.00         1\n",
            "          14       0.00      0.00      0.00         1\n",
            "          15       0.00      0.00      0.00         1\n",
            "          17       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.90       199\n",
            "   macro avg       0.38      0.36      0.37       199\n",
            "weighted avg       0.87      0.90      0.88       199\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.92      0.91        50\n",
            "           1       0.91      0.98      0.94        98\n",
            "           2       0.88      0.71      0.79        21\n",
            "           4       1.00      1.00      1.00         1\n",
            "           5       0.56      0.62      0.59         8\n",
            "           6       1.00      1.00      1.00        14\n",
            "           7       0.00      0.00      0.00         1\n",
            "           8       0.00      0.00      0.00         1\n",
            "           9       0.00      0.00      0.00         1\n",
            "          11       0.00      0.00      0.00         1\n",
            "          12       0.00      0.00      0.00         1\n",
            "          14       1.00      1.00      1.00         1\n",
            "          15       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.89       199\n",
            "   macro avg       0.48      0.48      0.48       199\n",
            "weighted avg       0.87      0.89      0.88       199\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94        49\n",
            "           1       0.93      0.97      0.95        98\n",
            "           2       0.70      0.73      0.71        22\n",
            "           3       0.00      0.00      0.00         1\n",
            "           5       0.80      0.44      0.57         9\n",
            "           6       1.00      0.93      0.96        14\n",
            "           7       0.00      0.00      0.00         1\n",
            "           8       0.00      0.00      0.00         2\n",
            "          10       0.00      0.00      0.00         1\n",
            "          13       0.00      0.00      0.00         1\n",
            "          14       0.00      0.00      0.00         1\n",
            "          15       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.89       199\n",
            "   macro avg       0.36      0.34      0.34       199\n",
            "weighted avg       0.86      0.89      0.87       199\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97        50\n",
            "           1       0.97      0.97      0.97        97\n",
            "           2       0.68      0.86      0.76        22\n",
            "           3       0.00      0.00      0.00         1\n",
            "           5       0.67      0.50      0.57         8\n",
            "           6       1.00      1.00      1.00        14\n",
            "           7       0.00      0.00      0.00         1\n",
            "           8       0.00      0.00      0.00         2\n",
            "          13       0.00      0.00      0.00         1\n",
            "          14       1.00      1.00      1.00         1\n",
            "          15       0.00      0.00      0.00         1\n",
            "          16       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.91       199\n",
            "   macro avg       0.44      0.44      0.44       199\n",
            "weighted avg       0.89      0.91      0.90       199\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.94        50\n",
            "           1       0.91      0.97      0.94        97\n",
            "           2       0.75      0.68      0.71        22\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.50      1.00      0.67         1\n",
            "           5       0.75      0.38      0.50         8\n",
            "           6       1.00      1.00      1.00        14\n",
            "           7       0.00      0.00      0.00         1\n",
            "           8       0.00      0.00      0.00         1\n",
            "          13       0.00      0.00      0.00         1\n",
            "          14       1.00      1.00      1.00         1\n",
            "          15       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.89       198\n",
            "   macro avg       0.49      0.50      0.48       198\n",
            "weighted avg       0.87      0.89      0.88       198\n",
            "\n",
            "[0.36503502 0.47921358 0.34481753 0.43923315 0.48027167]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier, BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import f1_score, classification_report, make_scorer\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "def report_f1(y_true, y_pred):\n",
        "    print(classification_report(y_true, y_pred, zero_division=0.0))\n",
        "    return f1_score(y_true, y_pred, average='macro', zero_division=0.0)\n",
        "\n",
        "# Initialize models\n",
        "bagging_model = BaggingClassifier()\n",
        "extratrees_model = ExtraTreesClassifier()\n",
        "xgboost_model = XGBClassifier()\n",
        "randomforest_model = RandomForestClassifier()\n",
        "gradboost_model = GradientBoostingClassifier()\n",
        "\n",
        "\n",
        "model = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('bg', bagging_model),\n",
        "        ('et', extratrees_model),\n",
        "        ('xgb', xgboost_model),\n",
        "        ('rf', randomforest_model),\n",
        "        ('gb', gradboost_model),\n",
        "    ], voting='hard'\n",
        ")\n",
        "\n",
        "# Train the model on the training data\n",
        "cv_f1_score = cross_val_score(model, X_train, y_train, fit_params={'sample_weight': sample_wts}, scoring=make_scorer(report_f1))\n",
        "print(cv_f1_score)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
