{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ftGaqLZDbwIX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create imputer object\n",
        "imputer = IterativeImputer(max_iter=100, tol=1e-3)\n",
        "\n",
        "df = pd.read_csv('data/iith_foml_2023_train.csv')\n",
        "y_train = df.iloc[:, -1]\n",
        "X_train = df.iloc[:, :-1]\n",
        "# Fit the imputer model on the dataset to learn the data patterns\n",
        "X_train.drop(columns=['Feature 16', 'Feature 17', 'Feature 18'], inplace=True)\n",
        "imputer.fit(X_train)\n",
        "\n",
        "# Transform the dataset to replace missing values\n",
        "# Convert back to a DataFrame\n",
        "X_train_imputed = pd.DataFrame(imputer.transform(X_train), columns=X_train.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test = pd.read_csv('data/iith_foml_2023_test.csv')\n",
        "df_test.drop(columns=['Feature 16', 'Feature 17', 'Feature 18'], inplace=True)\n",
        "X_test = pd.DataFrame(imputer.transform(df_test), columns=df_test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier, BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
        "\n",
        "# Initialize models\n",
        "bagging_model = BaggingClassifier()\n",
        "extratrees_model = ExtraTreesClassifier()\n",
        "randomforest_model = RandomForestClassifier()\n",
        "\n",
        "model = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('rf', randomforest_model),\n",
        "        ('bg', bagging_model),\n",
        "        ('et', extratrees_model)\n",
        "    ], voting='hard'\n",
        ")\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "predictions = model.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_df = pd.DataFrame()\n",
        "pred_df['Category'] = predictions\n",
        "pred_df['id'] = pred_df.index + 1\n",
        "pred_df = pred_df[['id', 'Category']]\n",
        "pred_df.to_csv('output/voting.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
