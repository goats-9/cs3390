{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the Machine Learning Model\n",
    " \n",
    "### Authors\n",
    "\n",
    "| Name | Roll Number |\n",
    "| - | - |\n",
    "| Gautam Singh | CS21BTECH11018 |\n",
    "| Jaswanth Beere | BM21BTECH11007 |\n",
    "\n",
    "This `.ipynb` file trains a Poisson regression model on the data, and compares its performance on some test data to a standard linear regression model trained on the same data.\n",
    "\n",
    "## Package Imports\n",
    "\n",
    "The packages required for this exercise are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Datasets\n",
    "\n",
    "The `pandas` library is used to load the `csv` datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://docs.google.com/spreadsheets/d/1KcLviro0OqVX3H1VcgamF_4dPOiXQymfJKSgvhUiAx4/export?gid=836855799&format=csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analaysis\n",
    "\n",
    "In this section, we perform an exploratory data analysis on the given dataset by plotting the time taken to complete meals of each type for a given day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe for EDA\n",
    "df = df.sort_values(\"day\").reset_index(drop=True)\n",
    "\n",
    "# Strings for plots and legend\n",
    "meal_type_meanings = [\"Morning\", \"Breakfast\", \"Mid-morning\", \"Lunch\", \"Evening\", \"Dinner\"]\n",
    "day_meanings = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n",
    "plt.figure(figsize=(10, 5))\n",
    "for meal_type in range(6):\n",
    "    # Filter data for the specific meal type\n",
    "    filtered_data = [df['meal_duration'][i] for i in range(len(df['meal_type'])) if df['meal_type'][i] == meal_type]\n",
    "    days = [day_meanings[df['day'][i]] for i in range(len(df['meal_type'])) if df['meal_type'][i] == meal_type]\n",
    "  \n",
    "    # Plotting\n",
    "    plt.scatter(days, filtered_data, label=f\"{meal_type_meanings[meal_type]}\")\n",
    "\n",
    "# Aesthetics\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.xlabel('Days in a week')\n",
    "plt.ylabel('Meal Duration ( minutes )')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"Meal Duration Against Different Days for Each Meal Type\", pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "The `start_time` feature contains the time (in 24-hour format `HHMM`) when the subject started eating their meal. It must be normalized to make it a suitable feature for applying the Poisson regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_time'] = df['start_time'].apply(lambda x: (int(str(x)[0]) * 60 + int(str(x)[1:])) if x < 999 else (int(str(x)[:2]) * 60 + int(str(x)[2:])))\n",
    "df['start_time'] = df['start_time']/(24*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the data is sampled using _random sampling_. 80 percent of this data is _training dataset_, and the remaining 20 percent becomes the _test dataset_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle the data\n",
    "shuffled_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split the data: 80% for training and 20% for testing\n",
    "split_index = int(0.8 * len(shuffled_df))\n",
    "train_df = shuffled_df.iloc[:split_index]\n",
    "test_df = shuffled_df.iloc[split_index:]\n",
    "\n",
    "print(f\"Total: {len(df)}, Train: {len(train_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### Poisson Regression\n",
    "\n",
    "The Poisson regression model is set up and trained in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate independent and dependent variables\n",
    "X = train_df.drop(columns='meal_duration').to_numpy()\n",
    "y = train_df['meal_duration'].to_numpy()\n",
    "X = np.hstack([np.ones((X.shape[0], 1)), X])  # Add bias/intercept term\n",
    "\n",
    "# Poisson regression via gradient ascent\n",
    "def compute_lambda(X, beta):\n",
    "    return np.exp(X @ beta)\n",
    "\n",
    "def gradient_log_likelihood(X, y, beta):\n",
    "    lambda_ = compute_lambda(X, beta)\n",
    "    return X.T @ (y - lambda_)\n",
    "\n",
    "def poisson_regression_GD(X, y, eta=1e-6, num_iter=1e5):\n",
    "    beta = np.zeros(X.shape[1])\n",
    "    for i in range(int(num_iter)):\n",
    "        gradient = gradient_log_likelihood(X, y, beta)\n",
    "        beta += eta * gradient  # gradient ascent since we maximize log-likelihood\n",
    "    return beta\n",
    "\n",
    "# Training the model\n",
    "beta = poisson_regression_GD(X, y)\n",
    "\n",
    "# Analyzing the importance of parameters\n",
    "importance = abs(beta)\n",
    "sorted_indices = np.argsort(importance)[::-1]\n",
    "column_names = ['bias'] + train_df.drop(columns='meal_duration').columns.tolist()\n",
    "\n",
    "# Display learned parameters\n",
    "print(\"Learned parameters:\")\n",
    "for idx in sorted_indices:\n",
    "    print(f\"{column_names[idx]}: {importance[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the learned parameters, the more important parameters are those with a larger absolute weight, such as `num_courses`, `start_time`, `is_holiday` and `location`. Qualitatively, these do make sense as factors that can affect mealtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "The `scikit-learn` has an out-of-the box implementation for linear regression, which is used on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear regression model to the data\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "The _root mean squared error_ (RMSE) is used as an evaluation metric.\n",
    "\n",
    "### Poisson Regression\n",
    "\n",
    "The code cell below evaluates the RMSE for the Poisson regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the learned Poisson regression model\n",
    "X_test = test_df.drop(columns='meal_duration').to_numpy()\n",
    "X_test = np.hstack([np.ones((X_test.shape[0], 1)), X_test])  # Add bias/intercept term\n",
    "predictions = np.exp(X_test @ beta)\n",
    "\n",
    "# Function to compute root mean squared error given true data\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)**0.5\n",
    "\n",
    "# Extract actual values from test_df\n",
    "y_test = test_df['meal_duration'].to_numpy()\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = root_mean_squared_error(y_test, predictions)\n",
    "\n",
    "print(f\"Poisson Regression RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "The code cell below evaluates the RMSE for the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find model predictions on test data\n",
    "lr_predictions = lr.predict(X_test)\n",
    "\n",
    "# Compute RMSE for linear regression\n",
    "rmse_lr = root_mean_squared_error(y_test, lr_predictions)\n",
    "\n",
    "print(f\"Linear Regression RMSE: {rmse_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Though time-series data was used, it turns out that linear regression performs better than Poisson regression. This is because of the many optimizations `scikit-learn` have in their solvers for this model. Additionally, the dataset size is very small, which implies that it may not follow a Poisson distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
