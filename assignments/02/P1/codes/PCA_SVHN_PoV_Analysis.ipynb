{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "\n",
    "### Authors\n",
    "\n",
    "| Name | Roll Number |\n",
    "|-|-|\n",
    "| Gautam Singh | CS21BTECH11018 |\n",
    "| Jaswanth Beere | BM21BTECH11007 |\n",
    "\n",
    "This `.ipynb` notebook performs Principal Component Analysis (PCA) on the SVHN\n",
    "dataset.\n",
    "\n",
    "## Obtaining the Data\n",
    "\n",
    "The SVHN dataset is obtained using the `curl` command on the appropriate file\n",
    "URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -f train_32x32.mat ]; then\n",
    "    curl -O http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -f test_32x32.mat ]\n",
    "then\n",
    "    curl -O http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports\n",
    "\n",
    "For this exercise, the following packages must be installed and imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy scikit-learn scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import io\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "We begin by visualizing part of the raw data. First, we must load the data into\n",
    "`numpy` arrays for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test data\n",
    "\n",
    "train_data = io.loadmat('train_32x32.mat')\n",
    "test_data = io.loadmat('test_32x32.mat')\n",
    "\n",
    "# Separate training data inputs (images) and outputs (classes)\n",
    "\n",
    "train_X = train_data['X']\n",
    "train_Y = train_data['y']\n",
    "test_X = test_data['X']\n",
    "test_Y = test_data['y']\n",
    "\n",
    "NUM_TRAIN_SAMPLES = train_X.shape[-1]\n",
    "NUM_TEST_SAMPLES = test_X.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we reshape the dimensions of `train_X` such that the first index\n",
    "represents sample number. Further, we scale all features to zero mean and unit\n",
    "variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape train_X such that train_X[i] is the ith image in the dataset\n",
    "# Further, flatten image arrays for PCA.\n",
    "\n",
    "train_X_reshaped = train_X.reshape(32*32*3, NUM_TRAIN_SAMPLES).T\n",
    "test_X_reshaped = test_X.reshape(32*32*3, NUM_TEST_SAMPLES).T\n",
    "train_Y_reshaped = train_Y.ravel()\n",
    "test_Y_reshaped = test_Y.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling the Data\n",
    "\n",
    "To perform PCA on the given dataset, we sample 2500 data points of each digit\n",
    "from 0 to 9, giving us 25000 training examples to perform PCA on. Note that 0 is\n",
    "represented as 10 in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 2500 training examples for each digit\n",
    "NUM_SAMPLES_PER_CLASS = 2500\n",
    "\n",
    "# Use a numpy random number generator\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "# Array of randomly chosen indices\n",
    "ind_arr = np.array([])\n",
    "\n",
    "for i in range(1,11,1):\n",
    "    # Find the indices in the training set corresponding to digit\n",
    "    idx = np.where(train_Y == i)[0]\n",
    "    # Generate samples randomly\n",
    "    rand_samples = rng.choice(idx, NUM_SAMPLES_PER_CLASS, False)\n",
    "    # Append to index array\n",
    "    ind_arr = np.append(ind_arr, rand_samples)\n",
    "\n",
    "ind_arr = np.asarray(ind_arr, int)\n",
    "# Finally, generate random samples and their labels\n",
    "train_X_gen = train_X_reshaped[ind_arr]\n",
    "train_Y_gen = train_Y[ind_arr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now in a position to perform PCA on our training set and visualize how\n",
    "the proportion of variance (PoV) changes with the number of top eigenvectors\n",
    "considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA of the generated training set using only the top 10 eigenvectors\n",
    "pca = PCA(n_components=10)\n",
    "train_X_pca = pca.fit_transform(train_X_gen)\n",
    "\n",
    "# Perform PCA transform of the test data\n",
    "test_X_pca = pca.transform(test_X_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we visualize the top 10 eigenvectors and their eigenvalues. Then, we\n",
    "provide a reconstrcution of a sample from each class using these top 10\n",
    "eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of PCA components\n",
    "n_components = pca.n_components_\n",
    "# Visualize top 10 eigenvectors and eigenvalues\n",
    "print(pca.components_)\n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the reconstructed samples\n",
    "fig = plt.figure()\n",
    "# Note that each class has a starting index of 2500*i\n",
    "for i in range(10):\n",
    "    # Add subplot\n",
    "    sub = fig.add_subplot(2,5,i+1)\n",
    "    # Perform inverse pca transform\n",
    "    sub.imshow(np.asarray(pca.inverse_transform(train_X_pca[NUM_SAMPLES_PER_CLASS*i]), int).reshape(32,32,3))\n",
    "    sub.title.set_text('Digit ' + str((i+1)%10))\n",
    "\n",
    "fig.suptitle('Visualization of Images Using Top 10 Eigenvectors')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the images are not reconstructed clearly, as very few (10) eigenvectors\n",
    "are used compared to the dimension (3072) of the images in the PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PoV Against the Number of Eigenvectors\n",
    "\n",
    "To find the ideal number of eigenvectors to use in the PCA, we plot the\n",
    "Proportion of Variance (PoV) as a function of the number of eigenvectors\n",
    "considered. We set our threshold PoV to be 0.9 _i.e._, a 90% reconstruction of\n",
    "the image is ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA with ALL dimensions. This can take a while.\n",
    "full_pca = PCA()\n",
    "train_X_allpca = full_pca.fit(train_X_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PoV array (zero padded at the start)\n",
    "cumulative_variance = np.zeros(len(full_pca.explained_variance_ratio_) + 1)\n",
    "cumulative_variance[1:] = np.cumsum(full_pca.explained_variance_ratio_)\n",
    "\n",
    "# Plot the cumulative variance as well as cutoff 0.9 PoV\n",
    "plt.plot(cumulative_variance)\n",
    "plt.plot(np.arange(cumulative_variance.shape[0]), 0.9*np.ones_like(cumulative_variance), '--')\n",
    "plt.xlabel('Number of Eigenvectors')\n",
    "plt.ylabel('PoV')\n",
    "plt.title('Proportion of Variance (PoV) Against Number of Eigenvectors')\n",
    "plt.legend(['PoV of Data', 'Required PoV (0.9)'])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above figure, it is quite evident that the top 10 eigenvectors will be\n",
    "insufficient. To find the ideal number of eigenvectors, we can perform binary\n",
    "search on the `cumulative_variance` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_comp = np.searchsorted(cumulative_variance, 0.9)\n",
    "pca_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the ideal number of components needed for the PCA is 27."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN and PCA\n",
    "\n",
    "Now, we perform the k-nearest neighbours classification algorithm on the\n",
    "training dataset, with and without PCA. We also demonstrate the difference in\n",
    "test accuracy on using different number of eigenvectors for the PCA as found in\n",
    "the previous sections. Here, we consider `k = 5, 7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define kNN classifier objects\n",
    "neigh_five = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh_seven = KNeighborsClassifier(n_neighbors=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN on Raw Data\n",
    "\n",
    "The raw data obtained is directly run with kNN, and the accuracies are reported\n",
    "below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run kNN with k=5 and k=7. This might take a while.\n",
    "\n",
    "# Using k=5\n",
    "neigh_five = neigh_five.fit(train_X_gen, train_Y_gen.ravel())\n",
    "neigh_five_score_raw = neigh_five.score(test_X_reshaped, test_Y_reshaped)\n",
    "# Using k=7\n",
    "neigh_seven = neigh_seven.fit(train_X_gen, train_Y_gen.ravel())\n",
    "neigh_seven_score_raw = neigh_seven.score(test_X_reshaped, test_Y_reshaped)\n",
    "# Report accuracy\n",
    "print('Accuracy for raw data using k = 5:', neigh_five_score_raw)\n",
    "print('Accuracy for raw data using k = 7:', neigh_seven_score_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN on PCA Preprocessed Data\n",
    "\n",
    "To improve the accuracy (which is about 41.86%) of kNN, we perform it on the\n",
    "preprocessed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using 10 Eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run kNN with k=5 and k=7. This might take a while.\n",
    "\n",
    "# Using k=5\n",
    "neigh_five = neigh_five.fit(train_X_pca, train_Y_gen.ravel())\n",
    "neigh_five_score_raw = neigh_five.score(test_X_pca, test_Y_reshaped)\n",
    "# Using k=7\n",
    "neigh_seven = neigh_seven.fit(train_X_pca, train_Y_gen.ravel())\n",
    "neigh_seven_score_raw = neigh_seven.score(test_X_pca, test_Y_reshaped)\n",
    "# Report accuracy\n",
    "print('Accuracy for raw data using k = 5:', neigh_five_score_raw)\n",
    "print('Accuracy for raw data using k = 7:', neigh_seven_score_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using PoV = 0.9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
